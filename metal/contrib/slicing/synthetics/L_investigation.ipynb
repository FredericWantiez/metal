{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.utils import split_data\n",
    "from visualization_utils import visualize_data\n",
    "from data_generators import generate_pacman_data\n",
    "\n",
    "config = {\n",
    "    'N': 10000,\n",
    "    'mus': np.array([[0,  0], [5, 0]]),\n",
    "    'variances': [1.5, 5],\n",
    "    'labels': [2, 1],\n",
    "    'lf_metrics': [('recall', 1.0), ('recall', 1.0)],\n",
    "}\n",
    "\n",
    "X, Y, Z, L = generate_pacman_data(config)\n",
    "Ls, Xs, Ys, Zs = split_data(L, X, Y, Z, splits=[0.5, 0.25, 0.25], shuffle=True)\n",
    "\n",
    "# visualize_data(X, Y, Z, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.contrib.backends.snorkel_gm_wrapper import SnorkelLabelModel\n",
    "\n",
    "# replace GT with weak labels\n",
    "label_model = SnorkelLabelModel()\n",
    "label_model.train_model(Ls[0])\n",
    "Y_train = label_model.predict_proba(Ls[0])\n",
    "Ys[0] = Y_train\n",
    "\n",
    "# for testing LFs\n",
    "X_test = torch.Tensor(Xs[2])\n",
    "L_test = Ls[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm that we can recover the L matrix\n",
    "\n",
    "Train slice-aware model with `slice_weight=1.0`. \n",
    "Then, try to repredict the `L_test` values using the `L_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.contrib.slicing.experiment_utils import (\n",
    "    create_data_loader,\n",
    "    train_model,\n",
    "    train_slice_dp,\n",
    "    eval_model\n",
    ")\n",
    "from metal.contrib.slicing.utils import get_L_weights_from_targeting_lfs_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SliceDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/anaconda3/envs/metal/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/Users/bradenjh/repos/metal/metal/contrib/slicing/online_dp.py:159: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  A = F.softmax(self.forward_L(x)).unsqueeze(1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice Heads:\n",
      "Reweighting: True\n",
      "L_weights: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "Slice Weight: 1.0\n",
      "Input Network: Sequential(\n",
      "  (0): MLPModule(\n",
      "    (input_layer): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "L_head: Linear(in_features=5, out_features=3, bias=False)\n",
      "Y_head: Linear(in_features=10, out_features=2, bias=True)\n",
      "Criteria: BCEWithLogitsLoss() SoftCrossEntropyLoss()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/repos/metal/metal/contrib/slicing/online_dp.py:176: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(self.forward_Y(x)).data.cpu().numpy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 epo]: train/loss=0.202, valid/accuracy=0.967\n",
      "[2 epo]: train/loss=0.118, valid/accuracy=0.973\n",
      "[3 epo]: train/loss=0.102, valid/accuracy=0.967\n",
      "[4 epo]: train/loss=0.087, valid/accuracy=0.513\n",
      "[5 epo]: train/loss=0.074, valid/accuracy=0.500\n",
      "[6 epo]: train/loss=0.064, valid/accuracy=0.508\n",
      "[7 epo]: train/loss=0.057, valid/accuracy=0.497\n",
      "[8 epo]: train/loss=0.050, valid/accuracy=0.497\n",
      "[9 epo]: train/loss=0.046, valid/accuracy=0.497\n",
      "[10 epo]: train/loss=0.041, valid/accuracy=0.480\n",
      "[11 epo]: train/loss=0.037, valid/accuracy=0.499\n",
      "[12 epo]: train/loss=0.035, valid/accuracy=0.510\n",
      "[13 epo]: train/loss=0.033, valid/accuracy=0.503\n",
      "[14 epo]: train/loss=0.032, valid/accuracy=0.489\n",
      "[15 epo]: train/loss=0.031, valid/accuracy=0.482\n",
      "[16 epo]: train/loss=0.030, valid/accuracy=0.481\n",
      "[17 epo]: train/loss=0.030, valid/accuracy=0.498\n",
      "[18 epo]: train/loss=0.029, valid/accuracy=0.498\n",
      "[19 epo]: train/loss=0.029, valid/accuracy=0.522\n",
      "[20 epo]: train/loss=0.028, valid/accuracy=0.487\n",
      "Finished Training\n",
      "Accuracy: 0.499\n",
      "        y=1    y=2   \n",
      " l=1   1181    103   \n",
      " l=2   1199    117   \n",
      "SliceDPModel(\n",
      "  (network): Sequential(\n",
      "    (0): MLPModule(\n",
      "      (input_layer): Sequential(\n",
      "        (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=5, out_features=5, bias=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (criteria): SoftCrossEntropyLoss()\n",
      "  (criteria_L): BCEWithLogitsLoss()\n",
      "  (criteria_Y): SoftCrossEntropyLoss()\n",
      "  (L_head): Linear(in_features=5, out_features=3, bias=False)\n",
      "  (Y_head): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "predicted L distribution: [ 178 2490  259]\n",
      "accuracy over LF0: 0.9892349096501346\n",
      "accuracy over LF1: 0.994232987312572\n",
      "accuracy over LF2: 0.9888504421376394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradenjh/anaconda3/envs/metal/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from metal.contrib.slicing.online_dp import MLPModule\n",
    "from metal.metrics import accuracy_score\n",
    "\n",
    "\n",
    "train_kwargs = {\n",
    "    \"disable_prog_bar\": True,\n",
    "    \"verbose\": True,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lr\": 0.005,\n",
    "    \"l2\": 1e-7,\n",
    "}\n",
    "sm_dp_config = {\n",
    "    'slice_kwargs': {\n",
    "        'r': 5,\n",
    "        'slice_weight': 1.0,\n",
    "        'reweight': True\n",
    "    },\n",
    "    'train_kwargs': train_kwargs,\n",
    "    'input_module_class': MLPModule,\n",
    "    'input_module_init_kwargs': {\n",
    "        'input_dim': 2,\n",
    "        'output_dim': 5,\n",
    "        'middle_dims': [5],\n",
    "        'bias': True\n",
    "    }\n",
    "}\n",
    "model = train_slice_dp(sm_dp_config, Ls, Xs, Ys, Zs)\n",
    "print(model)\n",
    "\n",
    "# L_preds = model.predict_L_proba(X_test)\n",
    "L_preds = F.sigmoid(model.forward_L(X_test)).data.cpu().numpy()\n",
    "preds = (L_preds > 0.5) * 1\n",
    "\n",
    "L_gt = L_test.copy()\n",
    "L_gt[L_gt != 0] = 1\n",
    "print ('predicted L distribution:', np.sum(preds, axis=0))\n",
    "print ('accuracy over LF0:', accuracy_score(L_gt[:, 0], preds[:, 0]))\n",
    "print ('accuracy over LF1:', accuracy_score(L_gt[:, 1], preds[:, 1]))\n",
    "print ('accuracy over LF2:', accuracy_score(L_gt[:, 2], preds[:, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SliceHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.metrics import accuracy_score\n",
    "\n",
    "def calc_L_accuracy(model, data_loader):\n",
    "    X, L, Y = data_loader.dataset.data\n",
    "    L_probs = model.predict_L_proba(torch.Tensor(X))\n",
    "    L_preds = np.round(L_probs)\n",
    "    score = accuracy_score(L.reshape(-1,1), L_preds.reshape(-1,1))\n",
    "    return {\"train/acc\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (3): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Resetting base model parameters\n",
      "SliceHatModel(\n",
      "  (body): Sequential(\n",
      "    (0): IdentityModule()\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (L_head): Linear(in_features=5, out_features=3, bias=False)\n",
      "  (L_criteria): BCEWithLogitsLoss()\n",
      ")\n",
      "\n",
      "[1 epo]: train/loss=0.149, train/acc=0.901, valid/accuracy=0.915\n",
      "[2 epo]: train/loss=0.037, train/acc=0.659, valid/accuracy=0.915\n",
      "[3 epo]: train/loss=0.009, train/acc=0.659, valid/accuracy=0.915\n",
      "[4 epo]: train/loss=0.003, train/acc=0.659, valid/accuracy=0.915\n",
      "[5 epo]: train/loss=0.001, train/acc=0.659, valid/accuracy=0.915\n",
      "[6 epo]: train/loss=0.001, train/acc=0.659, valid/accuracy=0.915\n",
      "[7 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[8 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[9 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[10 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[11 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[12 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[13 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[14 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[15 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[16 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[17 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[18 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[19 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "[20 epo]: train/loss=0.000, train/acc=0.659, valid/accuracy=0.915\n",
      "Finished Training\n",
      "Accuracy: 0.915\n",
      "        y=1    y=2   \n",
      " l=1   2380    220   \n",
      " l=2     0      0    \n",
      "SliceHatModel(\n",
      "  (body): Sequential(\n",
      "    (0): IdentityModule()\n",
      "    (1): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=5, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (L_head): Linear(in_features=5, out_features=3, bias=False)\n",
      "  (L_criteria): BCEWithLogitsLoss()\n",
      ")\n",
      "predicted L distribution: [[1 1 1]]\n",
      "accuracy over LF0: 0.0661284121491734\n",
      "accuracy over LF1: 0.9523260284505959\n",
      "accuracy over LF2: 0.10149942329873125\n"
     ]
    }
   ],
   "source": [
    "end_model_init_kwargs = {\n",
    "    \"layer_out_dims\": [2, 5, 5, 2]\n",
    "}\n",
    "sm_hat_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "    \"slice_kwargs\": {\n",
    "        \"slice_weight\": 1.0,\n",
    "        \"reweight\": True,\n",
    "    },\n",
    "    \"train_kwargs\": {\n",
    "        \"n_epochs\": 20,\n",
    "        \"lr\": 0.001,\n",
    "        \"log_unit\": \"epochs\",\n",
    "        \"log_train_metrics_func\": calc_L_accuracy,\n",
    "        \"log_train_metrics\": [\"train/loss\", \"train/acc\"],\n",
    "        \"log_train_every\": 1,\n",
    "        \"log_valid_every\": 1,\n",
    "    }\n",
    "}\n",
    "\n",
    "model = train_model(sm_hat_config, Ls, Xs, Ys, Zs, model_key=\"hat\")\n",
    "print(model)\n",
    "\n",
    "L_preds = torch.sigmoid(abs(model.L_head(model.body(X_test))))\n",
    "preds = (L_preds > 0.5) * 1\n",
    "\n",
    "L_gt = L_test.copy()\n",
    "L_gt[L_gt != 0] = 1\n",
    "print('predicted L distribution:', np.unique(preds, axis=0))\n",
    "print('accuracy over LF0:', accuracy_score(L_gt[:, 0], preds[:, 0]))\n",
    "print('accuracy over LF1:', accuracy_score(L_gt[:, 1], preds[:, 1]))\n",
    "print('accuracy over LF2:', accuracy_score(L_gt[:, 2], preds[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metal]",
   "language": "python",
   "name": "conda-env-metal-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
