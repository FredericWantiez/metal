{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/dfs/scratch0/vschen/metal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 312\n",
    "\n",
    "import random\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import data_config\n",
    "from synthetics_utils import generate_synthetic_data\n",
    "from visualization_utils import visualize_data, display_scores, plot_slice_scores\n",
    "# X, Y, C, L = generate_synthetic_data(data_config, verbose=True)\n",
    "\n",
    "# # L[L[:, 2] != 0, 2] = 0 # remove LF2 to show data underneath\n",
    "# visualize_data(X, Y, C, L)\n",
    "# data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'N': 10000,\n",
    " 'mus': np.array([[-3.5,  0], [5, 0]]),\n",
    " 'labels': [-1, 1],\n",
    " 'props': [0.10, 0.90],\n",
    " 'variances': [3, 5],\n",
    " 'accs': np.array([0.99, 0.99]),\n",
    " 'covs': [('recall', 0.99),\n",
    "  ('recall', 0.99)],\n",
    "  'head_config': None,\n",
    "  'mv_normal': False\n",
    "}\n",
    "\n",
    "def generate_simple_data(config, x_var=None, x_range=None, verbose=False):\n",
    "    X, Y, C, L = generate_synthetic_data(config, verbose=True)\n",
    "\n",
    "    # LF1\n",
    "    L = np.zeros((config['N'], 2))\n",
    "    lf_num = 0\n",
    "    slice_0_label = -1\n",
    "    r = 3 #HACK\n",
    "    h, k = (-3.5, 0)\n",
    "\n",
    "    # shifts\n",
    "    h+=1\n",
    "\n",
    "    lf_idx = np.sqrt((X[:, 0] - h) ** 2 + (X[:, 1] - k) ** 2) < r\n",
    "    L[lf_idx, lf_num] = slice_0_label\n",
    "    \n",
    "    # LF1\n",
    "    lf_num = 1\n",
    "    slice_1_label = 1\n",
    "    r = 7 #HACK\n",
    "    h, k = (5, 0)\n",
    "\n",
    "    # shifts\n",
    "    h-=1\n",
    "\n",
    "    lf_idx = np.sqrt((X[:, 0] - h) ** 2 + (X[:, 1] - k) ** 2) < r\n",
    "    L[lf_idx, lf_num] = slice_1_label\n",
    "    \n",
    "    return X, Y, C, L\n",
    "\n",
    "X, Y, C, L = generate_simple_data(config)\n",
    "visualize_data(X, Y, C, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate, experiment_config\n",
    "split_idx = int(len(X) * experiment_config[\"train_prop\"])\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "Y_train, Y_test = Y[:split_idx], Y[split_idx:]  # no gt train data!\n",
    "L_train, L_test = L[:split_idx], L[split_idx:]\n",
    "C_train, C_test = C[:split_idx], C[split_idx:]\n",
    "\n",
    "accs = []\n",
    "from metal.metrics import accuracy_score\n",
    "for lf_idx in range(L_train.shape[1]):\n",
    "    voted_idx = L_test[:, lf_idx] != 0\n",
    "    accs.append(accuracy_score(L_test[voted_idx, lf_idx], Y_test[voted_idx]))\n",
    "\n",
    "print (accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.contrib.slicing.experiment_utils import generate_weak_labels\n",
    "Y_tilde = generate_weak_labels(L_train, np.array(accs))\n",
    "plt.hist(Y_tilde[:, 0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.contrib.slicing.online_dp import MLPModule, SliceDPModel\n",
    "\n",
    "model_configs = {\n",
    "    \"EndModel\": {\n",
    "        \"base_model_class\" : EndModel,\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"layer_out_dims\": [10, 2],\n",
    "            \"input_layer_config\": {\n",
    "                \"input_relu\": False,\n",
    "                \"input_batchnorm\": False,\n",
    "                \"input_dropout\": 0.0,\n",
    "            }\n",
    "        },\n",
    "        \"train_on_L\": False\n",
    "    },\n",
    "    \"AttentionModel\": {\n",
    "        \"base_model_class\" : SliceDPModel,\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"reweight\": True,\n",
    "            \"r\": 10,\n",
    "            \"slice_weight\": 0.5,\n",
    "            \"L_weights\": None\n",
    "        },\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"train_on_L\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['accs'] = np.array(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from simulate import simulate, experiment_config\n",
    "\n",
    "experiment_config['use_weak_labels_from_gen_model'] = False\n",
    "experiment_config['x_var'] = None\n",
    "experiment_config['num_trials'] = 1\n",
    "# experiment_config['x_range'] = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "experiment_config['verbose'] = True\n",
    "experiment_config['visualize_data'] = True\n",
    "experiment_config['train_kwargs']['print_every'] = 1\n",
    "experiment_config['train_kwargs']['l2'] = 0\n",
    "experiment_config['train_kwargs']['lr'] = 0.005\n",
    "experiment_config['train_kwargs']['n_epochs'] = 30\n",
    "experiment_config['seed'] = 444\n",
    "scores = \\\n",
    "    simulate(config, generate_simple_data, experiment_config, model_configs)\n",
    "# display_scores(scores, experiment_config['x_var'], [None])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import data_config as config\n",
    "\n",
    "config['accs'] = np.array([0.99, 0.99, 0.99, 0.99])\n",
    "config['covs'] = [('recall', 0.99), ('recall', 0.99), ('recall', 0.99), ('recall', 0.99)]\n",
    "config['head_config']['r'] = 1.2\n",
    "X, Y, C, L = generate_synthetic_data(config, verbose=True)\n",
    "\n",
    "# L[L[:, 2] != 0, 2] = 0 # remove LF2 to show data underneath\n",
    "visualize_data(X, Y, C, L)\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlapping slices of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import data_config as config\n",
    "\n",
    "config = {\n",
    "  'N': 10000,\n",
    " 'mus': [np.array([-5,  0]), np.array([3, 0])],\n",
    " 'labels': [1, 1],\n",
    " 'props': [0.05, 0.95],\n",
    " 'variances': [1, 5],\n",
    " 'head_config': {'h': -1, 'k': 0, 'r': 3, 'slice_label': -1},\n",
    " 'accs': np.array([0.99, 0.99, 0.99]),\n",
    " 'covs': [('recall', 0.99), ('recall', 0.99), ('precision', 0.75)]\n",
    "}\n",
    "X, Y, C, L = generate_synthetic_data(config, verbose=True)\n",
    "\n",
    "# L[L[:, 2] != 0, 2] = 0 # remove LF2 to show data underneath\n",
    "visualize_data(X, Y, C, L)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.contrib.slicing.online_dp import MLPModule, SliceDPModel\n",
    "\n",
    "model_configs = {\n",
    "    \"EndModel\": {\n",
    "        \"base_model_class\" : EndModel,\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"layer_out_dims\": [10, 2],\n",
    "            \"input_layer_config\": {\n",
    "                \"input_relu\": False,\n",
    "                \"input_batchnorm\": False,\n",
    "                \"input_dropout\": 0.0,\n",
    "            }\n",
    "        },\n",
    "        \"train_on_L\": False\n",
    "    },\n",
    "    \"UniformModel\": {\n",
    "        \"base_model_class\" : SliceDPModel,\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"reweight\": False,\n",
    "            \"r\": 10,\n",
    "            \"slice_weight\": 0.1,\n",
    "            \"L_weights\": np.array([1., 1., 1.]).astype(np.float32)\n",
    "        },\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"train_on_L\": True\n",
    "    },\n",
    "    \"ManualModel\": {\n",
    "        \"base_model_class\" : SliceDPModel,\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"reweight\": False,\n",
    "            \"r\": 10,\n",
    "            \"slice_weight\": 0.1,\n",
    "            \"L_weights\": np.array([1., 1., 5.]).astype(np.float32) # LF2 w/ 5x weight\n",
    "        },\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"train_on_L\": True\n",
    "    },\n",
    "    \"AttentionModel\": {\n",
    "        \"base_model_class\" : SliceDPModel,\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"reweight\": True,\n",
    "            \"r\": 10,\n",
    "            \"slice_weight\": 0.1,\n",
    "            \"L_weights\": None\n",
    "        },\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"train_on_L\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate, experiment_config\n",
    "\n",
    "experiment_config['use_weak_labels_from_gen_model'] = False\n",
    "experiment_config['x_var'] = None\n",
    "experiment_config['num_trials'] = 1\n",
    "# experiment_config['x_range'] = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "experiment_config['verbose'] = True\n",
    "experiment_config['visualize_data'] = True\n",
    "experiment_config['train_kwargs']['print_every'] = 1\n",
    "experiment_config['train_kwargs']['l2'] = 1e-4\n",
    "experiment_config['train_kwargs']['lr'] = 0.005\n",
    "experiment_config['train_kwargs']['n_epochs'] = 30\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['seed'] = 123\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['seed'] = 432\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slices in same class that are overlooked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import data_config as config\n",
    "\n",
    "config['accs'] = np.array([0.99, 0.99, 0.99, 0.99])\n",
    "config['covs'] = [('recall', 0.99), ('recall', 0.99), ('recall', 0.99), ('recall', 0.99)]\n",
    "config['head_config']['r'] = 1.2\n",
    "X, Y, C, L = generate_synthetic_data(config, verbose=True)\n",
    "\n",
    "# L[L[:, 2] != 0, 2] = 0 # remove LF2 to show data underneath\n",
    "visualize_data(X, Y, C, L)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metal.end_model import EndModel\n",
    "from metal.contrib.slicing.online_dp import MLPModule, SliceDPModel\n",
    "\n",
    "model_configs = {\n",
    "#     \"EndModel\": {\n",
    "#         \"base_model_class\" : EndModel,\n",
    "#         \"input_module_class\": MLPModule,\n",
    "#         \"input_module_init_kwargs\": {\n",
    "#             'input_dim': 2,\n",
    "#             'middle_dims': [10, 10],\n",
    "#             'bias': True,\n",
    "#             'output_dim': 10\n",
    "#          },\n",
    "#         \"base_model_init_kwargs\": {\n",
    "#             \"layer_out_dims\": [10, 2],\n",
    "#             \"input_layer_config\": {\n",
    "#                 \"input_relu\": False,\n",
    "#                 \"input_batchnorm\": False,\n",
    "#                 \"input_dropout\": 0.0,\n",
    "#             }\n",
    "#         },\n",
    "#         \"train_on_L\": False\n",
    "#     },\n",
    "#     \"UniformModel\": {\n",
    "#         \"base_model_class\" : SliceDPModel,\n",
    "#         \"base_model_init_kwargs\": {\n",
    "#             \"reweight\": False,\n",
    "#             \"r\": 10,\n",
    "#             \"slice_weight\": 0.5,\n",
    "#             \"L_weights\": np.array([1., 1., 1., 1.]).astype(np.float32)\n",
    "#         },\n",
    "#         \"input_module_class\": MLPModule,\n",
    "#         \"input_module_init_kwargs\": {\n",
    "#             'input_dim': 2,\n",
    "#             'middle_dims': [10, 10],\n",
    "#             'bias': True,\n",
    "#             'output_dim': 10\n",
    "#          },\n",
    "#         \"train_on_L\": True\n",
    "#     },\n",
    "#     \"ManualModel\": {\n",
    "#         \"base_model_class\" : SliceDPModel,\n",
    "#         \"base_model_init_kwargs\": {\n",
    "#             \"reweight\": False,\n",
    "#             \"r\": 10,\n",
    "#             \"slice_weight\": 0.5,\n",
    "#             \"L_weights\": np.array([1., 1., 5., 1.]).astype(np.float32) # LF2 w/ 5x weight\n",
    "#         },\n",
    "#         \"input_module_class\": MLPModule,\n",
    "#         \"input_module_init_kwargs\": {\n",
    "#             'input_dim': 2,\n",
    "#             'middle_dims': [10, 10],\n",
    "#             'bias': True,\n",
    "#             'output_dim': 10\n",
    "#          },\n",
    "#         \"train_on_L\": True\n",
    "#     },\n",
    "    \"AttentionModel\": {\n",
    "        \"base_model_class\" : SliceDPModel,\n",
    "        \"base_model_init_kwargs\": {\n",
    "            \"reweight\": True,\n",
    "            \"r\": 10,\n",
    "            \"slice_weight\": 0.5,\n",
    "            \"L_weights\": None\n",
    "        },\n",
    "        \"input_module_class\": MLPModule,\n",
    "        \"input_module_init_kwargs\": {\n",
    "            'input_dim': 2,\n",
    "            'middle_dims': [10, 10],\n",
    "            'bias': True,\n",
    "            'output_dim': 10\n",
    "         },\n",
    "        \"train_on_L\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulate, experiment_config\n",
    "experiment_config['use_weak_labels_from_gen_model'] = False\n",
    "experiment_config['x_var'] = None\n",
    "experiment_config['num_trials'] = 1\n",
    "# experiment_config['x_range'] = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "experiment_config['verbose'] = True\n",
    "experiment_config['visualize_data'] = True\n",
    "experiment_config['train_kwargs']['print_every'] = 1\n",
    "# experiment_config['train_kwargs']['l2'] = 1e-3\n",
    "experiment_config['train_kwargs']['l2'] = 0\n",
    "experiment_config['train_kwargs']['lr'] = 0.005\n",
    "experiment_config['train_kwargs']['n_epochs'] = 50\n",
    "experiment_config['train_kwargs']['scheduler_config'] = {\n",
    "            \"verbose\": True,\n",
    "            \"scheduler\": \"exponential\",\n",
    "            # ['constant', 'exponential', 'reduce_on_plateau']\n",
    "            # Freeze learning rate initially this many epochs\n",
    "            \"lr_freeze\": 0,\n",
    "            # Scheduler - exponential\n",
    "            \"exponential_config\": {\"gamma\": 0.9},  # decay rate\n",
    "            # Scheduler - reduce_on_plateau\n",
    "            \"plateau_config\": {\n",
    "                \"factor\": 0.1,\n",
    "                \"patience\": 0,\n",
    "                \"threshold\": 0.0001,\n",
    "                \"min_lr\": 1e-7,\n",
    "                \"verbose\": True,\n",
    "                \"mode\":'max'\n",
    "            },\n",
    "        }\n",
    "\n",
    "experiment_config['seed'] = 321\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "experiment_config['seed'] = 111\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['seed'] = 432\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_config['seed'] = 1515\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment_config['seed'] = 33\n",
    "scores = \\\n",
    "    simulate(config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(scores, experiment_config['x_var'], [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_on_slices(model, X_test, Y_test, C_test):\n",
    "#     S0_idx, S1_idx, S2_idx = (\n",
    "#         np.where(C_test == 0)[0],\n",
    "#         np.where(C_test == 1)[0],\n",
    "#         np.where(C_test == 2)[0],\n",
    "#     )\n",
    "#     eval_dict = {\"S0\": S0_idx, \"S1\": S1_idx, \"S2\": S2_idx}\n",
    "\n",
    "#     preds, Y = model._get_predictions((X_test, Y_test), return_probs=False)\n",
    "    \n",
    "#     print (\"S0:\", np.sum((preds == Y)[S0_idx]) / len(Y[S0_idx]))\n",
    "#     print (\"S1:\", np.sum((preds == Y)[S1_idx]) / len(Y[S1_idx]))\n",
    "#     print (\"S2:\", np.sum((preds == Y)[S2_idx]) / len(Y[S2_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accs = data_config['accs']\n",
    "\n",
    "# split_idx = int(len(X) * 0.8)\n",
    "\n",
    "# X = torch.Tensor(X)\n",
    "# # X = X.astype(np.float32)\n",
    "# Y_cat = Y.copy().astype(np.int32)\n",
    "# Y_cat[Y==-1] = 2\n",
    "# X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "# Y_train, Y_test = Y_cat[:split_idx], Y_cat[split_idx:]\n",
    "# L_train, L_test = L[:split_idx], L[split_idx:]\n",
    "# C_train, C_test = C[:split_idx], C[split_idx:]\n",
    "\n",
    "# from metal.contrib.slicing.experiment_utils import generate_weak_labels\n",
    "# Y_tilde = generate_weak_labels(L_train, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # from simulate import simulate, data_config, experiment_config, model_configs\n",
    "# from simulate import simulate, data_config, experiment_config\n",
    "\n",
    "# experiment_config['use_weak_labels_from_gen_model'] = False\n",
    "# experiment_config['visualize_data'] = True\n",
    "# experiment_config['seed'] = seed\n",
    "# experiment_config['x_var'] = 'sp'\n",
    "# experiment_config['x_range'] = [0.1]\n",
    "# experiment_config['num_trials'] = 2\n",
    "# experiment_config['train_kwargs']['print_every'] = 1\n",
    "# experiment_config['verbose'] = True\n",
    "# sp_scores = \\\n",
    "#     simulate(data_config, generate_synthetic_data, experiment_config, model_configs)\n",
    "# display_scores(sp_scores, experiment_config['x_var'], experiment_config['x_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary Slice Porportion \n",
    "_Ratio fo Green to Orange in Top Right figure_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating: sp=0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23e31a408a8490ab573e7572724929d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "\n",
      "Simulating: sp=0.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd21a4bae1bc4e1882ca0a9a6dece35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "\n",
      "Simulating: sp=0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69749432209a46a39f20e4fb8f6f9688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "Hardcoding 2 -> cat labels\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EndModel</th>\n",
       "      <th>UniformModel</th>\n",
       "      <th>ManualModel</th>\n",
       "      <th>AttentionModel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp: 0.05</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.970986</td>\n",
       "      <td>0.969052</td>\n",
       "      <td>0.970986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.944961</td>\n",
       "      <td>0.947105</td>\n",
       "      <td>0.944961</td>\n",
       "      <td>0.947105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.956375</td>\n",
       "      <td>0.959125</td>\n",
       "      <td>0.956625</td>\n",
       "      <td>0.959125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EndModel  UniformModel  ManualModel  AttentionModel\n",
       "sp: 0.05                                                     \n",
       "S0        0.970986      0.970986     0.969052        0.970986\n",
       "S1        0.944961      0.947105     0.944961        0.947105\n",
       "overall   0.956375      0.959125     0.956625        0.959125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EndModel</th>\n",
       "      <th>UniformModel</th>\n",
       "      <th>ManualModel</th>\n",
       "      <th>AttentionModel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp: 0.125</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>0.901354</td>\n",
       "      <td>0.901354</td>\n",
       "      <td>0.901354</td>\n",
       "      <td>0.901354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.900236</td>\n",
       "      <td>0.901021</td>\n",
       "      <td>0.901021</td>\n",
       "      <td>0.901021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.898125</td>\n",
       "      <td>0.899375</td>\n",
       "      <td>0.899375</td>\n",
       "      <td>0.899375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           EndModel  UniformModel  ManualModel  AttentionModel\n",
       "sp: 0.125                                                     \n",
       "S0         0.901354      0.901354     0.901354        0.901354\n",
       "S1         0.900236      0.901021     0.901021        0.901021\n",
       "overall    0.898125      0.899375     0.899375        0.899375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EndModel</th>\n",
       "      <th>UniformModel</th>\n",
       "      <th>ManualModel</th>\n",
       "      <th>AttentionModel</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp: 0.2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>0.845261</td>\n",
       "      <td>0.733075</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>0.837031</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.837884</td>\n",
       "      <td>0.837884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         EndModel  UniformModel  ManualModel  AttentionModel\n",
       "sp: 0.2                                                     \n",
       "S0       0.845261      0.733075     0.851064        0.851064\n",
       "S1       0.837031      0.709898     0.837884        0.837884\n",
       "overall  0.838500      0.718250     0.841000        0.841000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from simulate import simulate, data_config, experiment_config, model_configs\n",
    "experiment_config['use_weak_labels_from_gen_model'] = True\n",
    "experiment_config['x_var'] = 'sp'\n",
    "experiment_config['num_trials'] = 1\n",
    "# experiment_config['x_range'] = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
    "experiment_config['x_range'] = np.linspace(0.05, 0.2, 3)\n",
    "experiment_config['verbose'] = False\n",
    "experiment_config['seed'] = False\n",
    "sp_scores = \\\n",
    "    simulate(data_config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(sp_scores, experiment_config['x_var'], experiment_config['x_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_scores(sp_scores, xlabel=\"Slice Proportion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary Head LF Accuracy\n",
    "_blue to orange dots in bottom right figure_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from simulate import simulate, experiment_config, model_configs\n",
    "data_config['head_config']['r'] = 2\n",
    "experiment_config['use_weak_labels_from_gen_model'] = True\n",
    "experiment_config['x_var'] = 'acc'\n",
    "experiment_config['num_trials'] = 10\n",
    "experiment_config['x_range'] = [0.8, 0.85, 0.9, 0.95]\n",
    "lf_acc_scores = \\\n",
    "    simulate(data_config, generate_synthetic_data, experiment_config, model_configs)\n",
    "\n",
    "display_scores(lf_acc_scores, experiment_config['x_var'], experiment_config['x_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_scores(lf_acc_scores, xlabel=\"Head Accuracy\", \n",
    "                  custom_xranges={'S2': [0.8, 0.85, 0.9, 0.95]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary Head LF Precision\n",
    "_num of blue dots in red slice over num points in slice in bottom right_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from simulate import simulate, experiment_config, model_configs\n",
    "\n",
    "data_config['head_config']['r'] = 2\n",
    "experiment_config['use_weak_labels_from_gen_model'] = True\n",
    "experiment_config['x_var'] = 'cov.precision'\n",
    "experiment_config['num_trials'] = 10\n",
    "experiment_config['x_range'] = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "lf_prec_scores = \\\n",
    "    simulate(data_config, generate_synthetic_data, experiment_config, model_configs)\n",
    "\n",
    "display_scores(lf_prec_scores, experiment_config['x_var'], experiment_config['x_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_scores(lf_prec_scores, xlabel=\"Head LF Precision\")\n",
    "#                   custom_ylims={\"S2\":[0, 0.2]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary Head LF Recall\n",
    "_num blue dots in red slice over num red dots in bottom right_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from simulate import simulate, data_config, experiment_config, model_configs\n",
    "\n",
    "data_config['head_config']['r'] = 2\n",
    "experiment_config['use_weak_labels_from_gen_model'] = True\n",
    "experiment_config['x_var'] = 'cov.recall'\n",
    "experiment_config['num_trials'] = 10\n",
    "# experiment_config['x_range'] = [0.95]\n",
    "# experiment_config['verbose'] = True\n",
    "experiment_config['x_range'] = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "\n",
    "\n",
    "lf_rec_scores = simulate(data_config, generate_synthetic_data, experiment_config, model_configs)\n",
    "display_scores(lf_rec_scores, experiment_config['x_var'], experiment_config['x_range'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slice_scores(lf_rec_scores, xlabel=\"Head LF Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
