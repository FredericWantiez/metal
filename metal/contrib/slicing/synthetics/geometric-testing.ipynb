{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from metal.contrib.slicing.synthetics.geometric_synthetics import generate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Pay attention to slice weight!\n"
     ]
    }
   ],
   "source": [
    "from metal.contrib.slicing.online_dp import SliceHatModel, MLPModule\n",
    "from metal.end_model import EndModel\n",
    "\n",
    "# NOTE: each model can take a \"train_kwargs\"\n",
    "\n",
    "### SHARED PIECES\n",
    "end_model_init_kwargs = {\n",
    "    \"layer_out_dims\": [2, 10, 10, 2],\n",
    "    \"verbose\": True,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lr\": 0.01,\n",
    "    \"l2\": 1e-7,\n",
    "}\n",
    "\n",
    "### FULL CONFIGS\n",
    "dp_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "}\n",
    "\n",
    "uni_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "}\n",
    "\n",
    "up_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "    \"upweight_search_space\": {\"range\": [1, 5]},\n",
    "    \"max_search\": 5\n",
    "}\n",
    "\n",
    "moe_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "    \"expert_train_kwargs\": {\"n_epochs\": 10, \"verbose\": False},\n",
    "    \"train_kwargs\": {\"verbose\": False},\n",
    "    \"gating_dim\": 5\n",
    "}\n",
    "\n",
    "print(\"WARNING: Pay attention to slice weight!\")\n",
    "sm_config = {\n",
    "    \"end_model_init_kwargs\": end_model_init_kwargs,\n",
    "    \"slice_kwargs\": {\n",
    "        \"slice_weight\": 0.0,\n",
    "        \"reweight\": False,\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pepper: 0.0\n",
      "Salt: 42\n",
      "[Trial 0]\n",
      "---------- Training UNI ----------\n",
      "Added pepper=0.0 random negatives on 0/20 LFs\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Saving model at iteration 0 with best score 0.667\n",
      "[E:0]\tTrain Loss: 0.658\tDev accuracy: 0.667\n",
      "Saving model at iteration 1 with best score 0.674\n",
      "[E:1]\tTrain Loss: 0.634\tDev accuracy: 0.674\n",
      "Saving model at iteration 2 with best score 0.688\n",
      "[E:2]\tTrain Loss: 0.626\tDev accuracy: 0.688\n",
      "Saving model at iteration 3 with best score 0.695\n",
      "[E:3]\tTrain Loss: 0.622\tDev accuracy: 0.695\n",
      "Saving model at iteration 4 with best score 0.713\n",
      "[E:4]\tTrain Loss: 0.624\tDev accuracy: 0.713\n",
      "Saving model at iteration 5 with best score 0.760\n",
      "[E:5]\tTrain Loss: 0.619\tDev accuracy: 0.760\n",
      "[E:6]\tTrain Loss: 0.622\tDev accuracy: 0.716\n",
      "[E:7]\tTrain Loss: 0.621\tDev accuracy: 0.686\n",
      "Saving model at iteration 8 with best score 0.794\n",
      "[E:8]\tTrain Loss: 0.620\tDev accuracy: 0.794\n",
      "[E:9]\tTrain Loss: 0.618\tDev accuracy: 0.794\n",
      "[E:10]\tTrain Loss: 0.618\tDev accuracy: 0.755\n",
      "[E:11]\tTrain Loss: 0.616\tDev accuracy: 0.737\n",
      "[E:12]\tTrain Loss: 0.612\tDev accuracy: 0.778\n",
      "[E:13]\tTrain Loss: 0.612\tDev accuracy: 0.770\n",
      "[E:14]\tTrain Loss: 0.613\tDev accuracy: 0.785\n",
      "Saving model at iteration 15 with best score 0.796\n",
      "[E:15]\tTrain Loss: 0.613\tDev accuracy: 0.796\n",
      "Saving model at iteration 16 with best score 0.799\n",
      "[E:16]\tTrain Loss: 0.614\tDev accuracy: 0.799\n",
      "[E:17]\tTrain Loss: 0.613\tDev accuracy: 0.740\n",
      "[E:18]\tTrain Loss: 0.613\tDev accuracy: 0.798\n",
      "[E:19]\tTrain Loss: 0.612\tDev accuracy: 0.792\n",
      "Restoring best model from iteration 16 with score 0.799\n",
      "Finished Training\n",
      "Accuracy: 0.799\n",
      "        y=1    y=2   \n",
      " l=1    675    362   \n",
      " l=2    141   1322   \n",
      "---------- Training UP ----------\n",
      "Added pepper=0.0 random negatives on 0/20 LFs\n",
      "\n",
      "Network architecture:\n",
      "Sequential(\n",
      "  (0): IdentityModule()\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (3): Linear(in_features=10, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "Could not find kwarg \"config\" in destination dict.\n",
      "Warning: WeightedLabelVoter only accepts k=2 class L_matrix.\n",
      "Saving model at iteration 0 with best score 0.668\n",
      "[E:0]\tTrain Loss: 0.691\tDev accuracy: 0.668\n",
      "Saving model at iteration 1 with best score 0.668\n",
      "[E:1]\tTrain Loss: 0.689\tDev accuracy: 0.668\n",
      "Saving model at iteration 2 with best score 0.674\n",
      "[E:2]\tTrain Loss: 0.688\tDev accuracy: 0.674\n",
      "[E:3]\tTrain Loss: 0.687\tDev accuracy: 0.674\n",
      "[E:4]\tTrain Loss: 0.687\tDev accuracy: 0.632\n",
      "[E:5]\tTrain Loss: 0.686\tDev accuracy: 0.674\n",
      "[E:6]\tTrain Loss: 0.686\tDev accuracy: 0.631\n",
      "[E:7]\tTrain Loss: 0.686\tDev accuracy: 0.574\n",
      "[E:8]\tTrain Loss: 0.686\tDev accuracy: 0.627\n",
      "[E:9]\tTrain Loss: 0.685\tDev accuracy: 0.660\n",
      "[E:10]\tTrain Loss: 0.685\tDev accuracy: 0.617\n",
      "[E:11]\tTrain Loss: 0.685\tDev accuracy: 0.627\n",
      "[E:12]\tTrain Loss: 0.685\tDev accuracy: 0.621\n",
      "[E:13]\tTrain Loss: 0.683\tDev accuracy: 0.648\n",
      "[E:14]\tTrain Loss: 0.684\tDev accuracy: 0.608\n",
      "[E:15]\tTrain Loss: 0.684\tDev accuracy: 0.614\n",
      "[E:16]\tTrain Loss: 0.684\tDev accuracy: 0.654\n",
      "[E:17]\tTrain Loss: 0.684\tDev accuracy: 0.602\n",
      "[E:18]\tTrain Loss: 0.684\tDev accuracy: 0.607\n",
      "[E:19]\tTrain Loss: 0.683\tDev accuracy: 0.641\n",
      "Restoring best model from iteration 2 with score 0.674\n",
      "Finished Training\n",
      "Accuracy: 0.674\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    816   1684   \n",
      "Could not find kwarg \"config\" in destination dict.\n",
      "Warning: WeightedLabelVoter only accepts k=2 class L_matrix.\n",
      "Saving model at iteration 0 with best score 0.674\n",
      "[E:0]\tTrain Loss: 0.687\tDev accuracy: 0.674\n",
      "[E:1]\tTrain Loss: 0.685\tDev accuracy: 0.641\n",
      "[E:2]\tTrain Loss: 0.685\tDev accuracy: 0.646\n",
      "[E:3]\tTrain Loss: 0.684\tDev accuracy: 0.656\n",
      "[E:4]\tTrain Loss: 0.684\tDev accuracy: 0.620\n",
      "[E:5]\tTrain Loss: 0.684\tDev accuracy: 0.642\n",
      "[E:6]\tTrain Loss: 0.685\tDev accuracy: 0.608\n",
      "[E:7]\tTrain Loss: 0.684\tDev accuracy: 0.623\n",
      "[E:8]\tTrain Loss: 0.683\tDev accuracy: 0.640\n",
      "[E:9]\tTrain Loss: 0.683\tDev accuracy: 0.622\n",
      "[E:10]\tTrain Loss: 0.682\tDev accuracy: 0.625\n",
      "[E:11]\tTrain Loss: 0.682\tDev accuracy: 0.648\n",
      "[E:12]\tTrain Loss: 0.683\tDev accuracy: 0.669\n",
      "[E:13]\tTrain Loss: 0.684\tDev accuracy: 0.658\n",
      "[E:14]\tTrain Loss: 0.683\tDev accuracy: 0.613\n",
      "[E:15]\tTrain Loss: 0.682\tDev accuracy: 0.654\n",
      "[E:16]\tTrain Loss: 0.684\tDev accuracy: 0.616\n",
      "[E:17]\tTrain Loss: 0.683\tDev accuracy: 0.608\n",
      "[E:18]\tTrain Loss: 0.682\tDev accuracy: 0.605\n",
      "[E:19]\tTrain Loss: 0.682\tDev accuracy: 0.622\n",
      "Restoring best model from iteration 0 with score 0.674\n",
      "Finished Training\n",
      "Accuracy: 0.674\n",
      "        y=1    y=2   \n",
      " l=1     0      0    \n",
      " l=2    816   1684   \n",
      "Could not find kwarg \"config\" in destination dict.\n",
      "Warning: WeightedLabelVoter only accepts k=2 class L_matrix.\n",
      "Saving model at iteration 0 with best score 0.674\n",
      "[E:0]\tTrain Loss: 0.686\tDev accuracy: 0.674\n",
      "[E:1]\tTrain Loss: 0.685\tDev accuracy: 0.674\n",
      "[E:2]\tTrain Loss: 0.686\tDev accuracy: 0.674\n",
      "[E:3]\tTrain Loss: 0.687\tDev accuracy: 0.626\n",
      "[E:4]\tTrain Loss: 0.685\tDev accuracy: 0.634\n",
      "[E:5]\tTrain Loss: 0.684\tDev accuracy: 0.608\n",
      "[E:6]\tTrain Loss: 0.684\tDev accuracy: 0.637\n",
      "[E:7]\tTrain Loss: 0.684\tDev accuracy: 0.674\n",
      "[E:8]\tTrain Loss: 0.685\tDev accuracy: 0.634\n",
      "[E:9]\tTrain Loss: 0.683\tDev accuracy: 0.610\n",
      "[E:10]\tTrain Loss: 0.684\tDev accuracy: 0.622\n",
      "[E:11]\tTrain Loss: 0.683\tDev accuracy: 0.655\n",
      "[E:12]\tTrain Loss: 0.683\tDev accuracy: 0.597\n",
      "Saving model at iteration 13 with best score 0.677\n",
      "[E:13]\tTrain Loss: 0.684\tDev accuracy: 0.677\n",
      "[E:14]\tTrain Loss: 0.684\tDev accuracy: 0.666\n",
      "[E:15]\tTrain Loss: 0.683\tDev accuracy: 0.622\n",
      "[E:16]\tTrain Loss: 0.684\tDev accuracy: 0.566\n",
      "[E:17]\tTrain Loss: 0.684\tDev accuracy: 0.603\n",
      "[E:18]\tTrain Loss: 0.683\tDev accuracy: 0.661\n",
      "[E:19]\tTrain Loss: 0.685\tDev accuracy: 0.651\n",
      "Restoring best model from iteration 13 with score 0.677\n",
      "Finished Training\n",
      "Accuracy: 0.677\n",
      "        y=1    y=2   \n",
      " l=1    600    591   \n",
      " l=2    216   1093   \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "\n",
    "from metal.label_model import MajorityLabelVoter\n",
    "from metal.utils import split_data\n",
    "from metal.contrib.backends.snorkel_gm_wrapper import SnorkelLabelModel\n",
    "from metal.contrib.slicing.experiment_utils import (\n",
    "    create_data_loader,\n",
    "    train_model,\n",
    "    search_upweighting_models,\n",
    "    eval_model\n",
    ")\n",
    "from metal.contrib.slicing.utils import get_L_weights_from_targeting_lfs_idx\n",
    "from metal.contrib.slicing.mixture_of_experts import train_MoE_model\n",
    "\n",
    "\n",
    "model_configs = {\n",
    "    \"UNI\": uni_config,\n",
    "    \"UP\": up_config,\n",
    "#     \"MoE\": moe_config,\n",
    "    \"DP\": dp_config,\n",
    "    \"SM\": sm_config,\n",
    "}\n",
    "\n",
    "NUM_TRIALS = 1\n",
    "NUM_SLICES = 4\n",
    "K = 2\n",
    "M = 20\n",
    "N = 10000\n",
    "unipolar = False\n",
    "pepper = 0.0\n",
    "print(f\"Pepper: {pepper}\")\n",
    "# A base to add to trial number to set a unique seed for each trial\n",
    "salt = 42 #np.random.randint(1e6)\n",
    "print(f\"Salt: {salt}\")\n",
    "\n",
    "\n",
    "history = defaultdict(list)\n",
    "for trial in range(NUM_TRIALS):\n",
    "    print(f\"[Trial {trial}]\")\n",
    "\n",
    "    L_kwargs = {'max_r': 7} if unipolar else {'max_r': 5} \n",
    "    Z_kwargs = {'num_slices': NUM_SLICES}\n",
    "    L, X, Y, Z, targeting_lfs_idx = generate_dataset(K, M, N, \n",
    "                                                     L_kwargs=L_kwargs,\n",
    "                                                     Z_kwargs=Z_kwargs,\n",
    "                                                     unipolar=unipolar,\n",
    "                                                     return_targeting_lfs=True,\n",
    "                                                     seed=(salt + trial),\n",
    "                                                     plotting=False)\n",
    "\n",
    "    Ls, Xs, Ys, Zs = split_data(L, X, Y, Z, splits=[0.5, 0.25, 0.25], shuffle=True)\n",
    "    L_train_raw = Ls[0].copy() # TEMP\n",
    "    \n",
    "    for model_name, model_config in model_configs.items():\n",
    "        print (\"-\"*10, \"Training\", model_name, \"-\"*10)\n",
    "\n",
    "        Ls[0] = L_train_raw.copy() # TEMP: Reset to unpeppered version\n",
    "        \n",
    "        # Generate weak labels:\n",
    "        if model_name == \"UNI\":\n",
    "            Y_train = MajorityLabelVoter().predict_proba(Ls[0])\n",
    "        else:\n",
    "            label_model = SnorkelLabelModel()\n",
    "            label_model.train_model(Ls[0])\n",
    "            Y_train = label_model.predict_proba(Ls[0])\n",
    "        Ys[0] = Y_train\n",
    "        \n",
    "        from metal.contrib.slicing.utils import add_pepper\n",
    "        Ls[0] = add_pepper(Ls[0], pepper)        \n",
    "        \n",
    "        # Train end model\n",
    "        if model_name == \"UNI\":\n",
    "            model = train_model(model_config, Ls, Xs, Ys, Zs)\n",
    "        elif model_name == 'UP':\n",
    "            # generates weighted Y_train and overwrites overwrites Ys[0] internally\n",
    "            model = search_upweighting_models(model_config, Ls, Xs, Ys, Zs, \n",
    "                                              targeting_lfs_idx, verbose=False)\n",
    "        elif model_name == \"MoE\":\n",
    "            model = train_MoE_model(model_config, Ls, Xs, Ys, Zs)\n",
    "        elif model_name == \"DP\":\n",
    "            model = train_model(model_config, Ls, Xs, Ys, Zs)\n",
    "        elif model_name == \"SM\":\n",
    "            model = train_model(model_config, Ls, Xs, Ys, Zs)        \n",
    "        else:\n",
    "            raise Exception(f\"Unrecognized model_name: {model_name}\")\n",
    "            \n",
    "        test_loader = create_data_loader(Ls, Xs, Ys, Zs, model_config, 'test')\n",
    "        results = eval_model(model, test_loader, verbose=False, summary=False)        \n",
    "        \n",
    "        # Save results\n",
    "        history[model_name].append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from metal.contrib.slicing.experiment_utils import parse_history\n",
    "\n",
    "print(f\"Average (n={NUM_TRIALS}):\")\n",
    "df = parse_history(history, NUM_SLICES)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metal.contrib.visualization.analysis import view_label_matrix\n",
    "view_label_matrix(Ls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
